GAT，GCN

zero-shot：训练过猫和狗借助辅助信息实现对没出现过的种类比如马等的泛化(没有马的数据)

few-shot：K-shot(每个类别有 K 个标注样本)     N-way(任务中涉及 N 个不同类别)    

self-supervised learning：未标注数据，从数据内部结构中学习特征包括预训练和微调操作，通过大模型泛化适用于下游任务

supervised learning：标注数据，学习输入与标注之间的关系，一次性完成训练，受标注数据质量与数量限制

pre-training：通用数据集上对模型进行初步训练，学习通用特征或表示。

fine-tuning：将预训练的模型迁移到特定的下游任务上，通过在少量标注数据上进一步训练模型

downstream task：利用通用特征进行特定的、有目标的任务

consine similarity：一种用于衡量两个向量之间相似程度的指标，通过计算它们夹角的余弦值来确定$$cosine\_similarity(A,B)=\frac {A⋅B} {∥A∥∥B∥}$$

graph meta learning methods：图学习，从图数据（节点、边及其特征）中提取有用信息，用于任务如节点分类、边预测、图分类等。元学习，学习“如何学习”的框架，旨在从多个任务中提取跨任务的知识，使模型能够在少量数据上快速适应新任务。图元学习，将元学习的快速适应能力引入到图学习中，以应对图数据中的下游任务。
