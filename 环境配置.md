**miniconda安装**

https://blog.csdn.net/m0_64268260/article/details/144258371



**CUDA下载**

1.访问 [NVIDIA CUDA Toolkit 下载页面](https://developer.nvidia.com/cuda-downloads)。https://developer.nvidia.com/cuda-toolkit-archive

选择以下选项：

- **Operating System**: Linux
- **Architecture**: x86_64
- **Distribution**: Linux
- **Version**: 选择 "Runfile (local)"，因为 `.run` 文件可以在没有 `sudo` 权限的情况下安装。

在服务器上，你可以使用 `wget` 命令直接下载：

```bash
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
```

2. **解压并安装到本地用户目录**

3. **给 .run 文件赋予可执行权限**：

   ```bash
   chmod +x cuda_11.8.0_520.61.05_linux.run
   ```

4. **运行安装文件**（不使用 `sudo`）：

   ```bash
   ./cuda_11.8.0_520.61.05_linux.run --silent --toolkit --override --installpath=$HOME/cuda-11.8
   ```

   - 这会将 CUDA Toolkit 安装到你用户目录的 `$HOME/cuda-11.8` 中。
   - 选项说明：
     - `--silent`：静默安装模式，不需要交互。
     - `--toolkit`：只安装 CUDA Toolkit，不安装驱动（因为没有 `sudo` 权限）。
     - `--override`：忽略权限问题。
     - `--installpath`：指定安装路径为用户目录下的 `cuda-11.8`。

5. **验证安装**：

   ```
   ls $HOME/cuda-11.8
   ```

   你应该能看到 `bin`, `lib64` 等文件夹。

**3. 配置环境变量**

要确保你的系统能够找到 CUDA 可执行文件和库，需要设置环境变量。

- **编辑 `.bashrc` 文件**：

  ```bash
  nano ~/.bashrc
  ```

- **在文件末尾添加以下内容**：

  ```bash
  export PATH=$HOME/cuda-11.8/bin:$PATH
  export LD_LIBRARY_PATH=$HOME/cuda-11.8/lib64:$LD_LIBRARY_PATH
  ```

- **使配置生效**：

  ```bash
  source ~/.bashrc
  ```

**4. 验证 CUDA 安装**

- **查看 CUDA 版本**：

  ```bash
  nvcc --version
  ```

  输出应类似于：

  ```
  nvcc: NVIDIA (R) Cuda compiler driver
  Copyright (c) 2005-2022 NVIDIA Corporation
  Built on ....
  Cuda compilation tools, release 11.8, V11.8.89
  Build cuda_11.8.r11.8/compiler.31833905_0
  ```

**pytorch下载网址**

https://pytorch.org/get-started/locally/

老版本

https://pytorch.org/get-started/previous-versions/

**使用shell查看**

```shell
#显卡驱动信息，主要看CUDA支持的最高版本
nvidia-smi

#当前使用的CUDA的版本
nvcc -V

#查看安装了几个CUDA，当前使用哪个版本的CUDA
ll /usr/local/

#查看已安装的包的版本
conda list | grep cuda
conda list | grep torch

```

**使用py脚本查看**

vim version.py

```python
import torch
print(torch.__version__) # 查看torch版本
print(torch.cuda.is_available()) # 看安装好的torch和cuda能不能用，也就是看GPU能不能用
print(torch.version.cuda) # 输出一个 cuda 版本，注意：上述输出的 cuda 的版本并不一定是 Pytorch 在实际系统上运行时使用的 cuda 版本，而是编译该 Pytorch release 版本时使用的 cuda 版本，详见：https://blog.csdn.net/xiqi4145/article/details/110254093

import torch.utils
import torch.utils.cpp_extension
print(torch.utils.cpp_extension.CUDA_HOME) #输出 Pytorch 运行时使用的 cuda
```

显示类似

2.4.1
True
11.8
/home/wangchichu/cuda-11.8

**flash-attention安装**

官网下载https://github.com/Dao-AILab/flash-attention/releases对应版本的flash-attn

```bash
pip install flash_attn-2.6.3+cu118torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
```

```bash
python -c "import flash_attn; print(flash_attn.__version__)"
#验证是否安装成功
```

 
